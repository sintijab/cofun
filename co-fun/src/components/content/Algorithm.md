What are you listening now?

The sound references doesn't require the source of the streaming platforms. Train the AI with the information about moderators, the lists from the shows, and create the survey flow about the categories. The responses will aggregate metadata about the refined categories and attributes of the tracks, so it will be easier to group them and then give recommendations related to these new filters.
The data should not be publicly available, but AI should have access to the database of these collections.
Websockets will therefore
1.listen to the answers from the survey, request AI to validate the song, update the metadata on the DB
2 find the recommendations based on the selected categories
3.ask for the preferences and update the DB with the relationships between these categories
4.return recommendations based on information about the song
It would be also interesting to show the selected keyword groups in results and ask about the preferences of the similar tracks.